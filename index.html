<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yekyung Kim</title>
  
  <meta name="author" content="Yekyung Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="images/grogu_pixel.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yekyung Kim</name>
              </p>
              <p>
		      Hi! I am a second year PhD student at <a href="https://wiki.umiacs.umd.edu/clip/index.php/Main_Page">University of Maryland, CLIP Lab</a> advised by <a href="https://people.cs.umass.edu/~miyyer/"> Mohit Iyyer </a> with a research focus on natural language processing. I initially started my PhD at <a href="https://nlp.cs.umass.edu/">UMass NLP</a> and later transferred to UMD along with my advisor. 
              </p>
              <p>
		      Before starting PhD, I worked at Hyundai Motors Group and LG Electronics as a research engineer. I was fortunate to be selected as a <a href=http://www.koreatimes.co.kr/www/tech/2021/02/133_267589.html">specialist in AI</a> and researched at <a href="https://lti.cs.cmu.edu/">CMU LTI</a> as a visiting scientist mentored by <a href="https://www.cs.cmu.edu/~jgc/">Jaime Carbonell</a>.
              </p>
<!--               <p>In 2015, I received my master's degree with an outstanding paper award from Seoul National University, where I was in <a href="http://marg.snu.ac.kr"> Music and Audio Research Group (MARG)</a> advised by <a href="http://marg.snu.ac.kr/marg_people/">Kyogu Lee</a> and <a href="http://hcc.snu.ac.kr/wordpress/people/bongwon-suh">Bongwon Suh</a>.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:sigma89kim@gmail.com">Email</a> &nbsp/&nbsp
<!--                <a href="data/CV_Yekyung.pdf">CV</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.co.kr/citations?user=6Rn81SsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/mungg">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/IMG_9147.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/IMG_9147.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research goal is to build an <strong>efficient</strong> and <strong>trustworthy</strong>  system that connects humans and machines leveraging language as a bridge. I am interested in systems that make reliable communication between humans and machines and learn knowledge with as little human supervision as possible. In particular, my research directions include:
              </p>
              <p>
                1) <strong>Efficiency</strong>: Not all data are equally valuable in the real world for learning. How do we accurately calibrate the importance of data? How can we adjust models to new distribution resources efficiently?
              </p>
              <p>
                2) <strong>Generalization and Robustness</strong>: Models prefer to learn by shortcuts, but often face unexpected wild inputs. How can we detect various out-of-distribution data and make models generalized better from limited data?

              </p>
              <p>
              3) <strong>Trustfulness</strong>: Logical reasoning is a human’s hallmark capability that enables reliable communication. How can we control the model to give reliable answers expressing uncertainty? Is it possible for models to solve logic puzzles (ex., Einstein's Riddle) by comprehending problems and utilizing logical deduction? How can we teach models to reason logically with human guidance?
              </p>
<!--                -->
<!--                My research goal is to build an <strong>efficient</strong> and <strong>trustworthy</strong> system that connects humans and machines leveraging language as a bridge.-->
<!--                I am interested in how to make reliable communication between humans and machines and how machine learn knowledge with as little human supervision as possible.-->
<!--                In particular, my research directions include:  </p>-->
<!--              <p>-->
<!--              1) <strong>Efficiency</strong>: Given limited resources, how can we improve model under data-efficient fashion? Can we quantify the importance of data and categorize their characteristic?-->
<!--              </p>-->
<!--              <p>-->
<!--                2) <strong>Generalization and Robustness</strong>: How can we develop models to learn to generate data for better generalization? How can we make model giving reliable answers in controllable way?-->
<!--                 </p>-->
<!--              <p>-->
<!--                3) <strong>Logical reasoning</strong>: How can we expand machine knowledge with human guidance for logical reasoning?-->
<!--                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.-->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
	<tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/VeriScore_img.png" width="160"></td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2406.19276">
                <papertitle>VERISCORE: Evaluating the Factuality of Verifiable Claims in Long-form Text Generation</papertitle>
              </a>
              <br>
		    Yixiao Song,
              <strong>Yekyung Kim</strong>,
		    Mohit Iyyer
              <br>
              <em> Accepted by EMNLP Findings 2024 </em>
              <br>
              <a href=https://github.com/Yixiao-Song/VeriScore>Code</a>
              <p></p>
              <p>
		       We propose VERISCORE, a metric for diverse long-form generation tasks that contain both verifiable and unverifiable content. VERISCORE can be effectively implemented with either closed or fine-tuned open-weight language models, and human evaluation confirms that VERISCORE’s extracted claims are more sensible than those from competing methods across eight different long-form tasks.            
	    </td>
          </tr>
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/FABLES_icon2.png" width="160"></td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2404.01261">
                <papertitle>FABLES: Evaluating Faithfulness and Content Selection in Book-length Summarization</papertitle>
              </a>
              <br>
              <strong>Yekyung Kim</strong>,
		    Yapei Chang,
		    Marzena Karpinska,
		    Aparna Garimella,
		    Varun Manjunatha,
		    Kyle Lo,
		    Tanya Goyal,
		    Mohit Iyyer
              <br>
              <em>COLM 2024 </em>
              <br>
<!--              <a href="TODO">arXiv</a>-->
<!--              /-->
              <a href=https://github.com/mungg/FABLES>Dataset + Code</a>
              <p></p>
              <p>
		      While long-context large language models (LLMs) can technically summarize book-length documents (>100K tokens), the length and complexity of the documents have so far prohibited evaluations of input-dependent aspects like faithfulness. In this paper, we conduct the first large-scale human evaluation of faithfulness and content selection on LLM-generated summaries of fictional books. </p>
            </td>
          </tr>

	<tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/UR_thumbnail.png" width="160"></td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2402.06794">
                <papertitle>Is it safe to cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing</papertitle>
              </a>
              <br>
		Hochul Hwang, 
		Sunjae Kwon,
              <strong>Yekyung Kim</strong>,
              <br>
		<em> 21st International Conference on Ubiquitous Robots </em>
              <br>
              <p></p>
              <p>
                This paper introduces an innovative approach that leverages vision-language models (VLMs) to interpret complex street crossing scenes, offering a potential advancement over conventional traffic signal recognition techniques.
              </p>
            </td>
          </tr>
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/LINDA_profile2.png" width="160"></td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2112.13969.pdf">
                <papertitle>LINDA: Unsupervised Learning to Interpolate in Natural Language Processing</papertitle>
              </a>
              <br>
              <strong>Yekyung Kim</strong>,
              Seohyeong Jeong,
              Kyunghyun Cho
              <br>
		<em>arXiv</em>
              <br>
              <p></p>
              <p>
                We propose an unsupervised learning approach to text interpolation for the purpose of data augmentation that does not require any heuristics nor manually crafted resources but learns to
interpolate between any pair of natural language sentences over a natural language manifold.              
	      </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/InfoVerse_profile.png" width="160"></td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://aclanthology.org/2023.acl-long.547/">
                <papertitle>A Universal Framework for Dataset Characterization with Multidimensional Meta-information </papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/view/jaehyungkim">Jaehyung Kim</a>
              <strong>Yekyung Kim</strong>,
              Karin Johanna Denton de Langis,
              Jinwoo Shin,
              Dongyeop Kang
              <br>
              <em>ACL 2023</em>
              <br>
<!--              <a href="TODO">arXiv</a>-->
<!--              /-->
              <a href=https://github.com/minnesotanlp/infoVerse">code</a>
              <p></p>
              <p>
                We propose a data-centric framework to construct a new feature space that can capture various characteristics of datasets and novel sampling method to select a set of data points that maximizes the group informativeness.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/metacraft_profile.png" width="160"></td>
            <td style="padding:20px;width:75%;vertical-align:middle">
             <a href="https://ojs.aaai.org/index.php/AAAI/article/view/30467">
                <papertitle>Meta-Crafting: Improved Detection of Out-of-distributed Texts via Crafting Metadata Space</papertitle>
              </a>
              <br>
              Ryan Koo,
              <strong>Yekyung Kim</strong>,
              Dongyeop Kang,
              Jaehyung Kim
              <br>
             <em> AAAI 2024 Student Abstract and Poster Program </em>
<!--                at European Chapter of the Association for Computational Linguistics  </em>, 2022-->
              <br>
<!--              <a href="TODO">arXiv</a>-->
<!--              /-->
<!--              <a href="TODO">code</a>-->
<!--              code will be released soon-->
              <p></p>
              <p>
                We propose Meta-Crafting: a unified method that can capture both background and semantic shifts.  Specifically, we construct a new discriminative feature space to detect OOD samples
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/Active_profile.png" width="160"></td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://aclanthology.org/2020.lifelongnlp-1.1.pdf">
                <papertitle>Deep Active Learning for Sequence Labeling Based on Diversity and Uncertainty in Gradient</papertitle>
              </a>
              <br>
              <strong>Yekyung Kim</strong>
              <br>
              <em>Workshop on Life-long Learning for Spoken Language Systems at AACL</em>, 2021
              <br>
<!--              <a href="https://arxiv.org/pdf/2011.13570.pdf">arXiv</a>-->
<!--              /-->
<!--              <a href="TODO">code</a>-->
              <p></p>
              <p>
                I demonstrate that the amount of labeled training data can be reduced using active learning when it incorporates both uncertainty and diversity in the sequence labeling task.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/Korean_profile.png" width="160"></td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://journals.flvc.org/FLAIRS/article/view/128509">
                <papertitle>Learning Sub-Character level representation forKorean Named Entity Recognition</papertitle>
              </a>
              <br>
              Yejin Kim,
              <strong>Yekyung Kim</strong> (equal contributions)
              <br>
              <em>The International FLAIRS Conference Proceedings </em>, 2020
              <br>
<!--              <a href="https://journals.flvc.org/FLAIRS/article/view/128509">paper</a>-->
              <p></p>
              <p>
                We propose a improved unigram-level Korean NER model with sub-character level representation, jamo, which can represent a unique linguistic structure of Korean and its syntactic properties and morphological variations.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/Music_Twitter_profile.png" width="160"></td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/2632188.2632206">
                <papertitle>#Nowplaying the Future Billboard: Mining Music Listening Behaviors of Twitter Users for Hit Song Prediction</papertitle>
              </a>
              <br>
              <strong>Yekyung Kim</strong>,
              Bongwon Suh,
              Kyogu Lee
              <br>
              <em>Workshop on Social Media Retrieval and Analysis (SoMeRA) at SIGIR </em>, 2014
              <br>
<!--              <a href="https://dl.acm.org/doi/abs/10.1145/2632188.2632206">paper</a>-->
              <p></p>
              <p>
                We collect users' music listening behavior from Twitter using music-related hashtags (eg,# nowplaying). We then build a predictive model to forecast the Billboard rankings and hit music.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/Adobe_Twitter_profile.png" width="160"></td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://david-hawking.net/SIRIP2014_Proceedings/SIRIP'14-A%20Visual%20Analytics%20Approach%20to%20Summarizing%20Tweets.pdf">
                <papertitle>A Visual Analytics Approach to Summarizing Tweets</papertitle>
              </a>
              <br>
              Ramik Sadana,
              <strong>Yekyung Kim</strong> ,
              Bongwon Suh,
              Eunyee Koh
              <br>
              <em>Industry day at SIGIR </em>, 2014
              <br>
<!--              <a href="http://david-hawking.net/SIRIP2014_Proceedings/SIRIP'14-A%20Visual%20Analytics%20Approach%20to%20Summarizing%20Tweets.pdf">paper</a>-->
              <p></p>
              <p>
               We build on key principles of visual analytics and describe an end-to-end, visual exploration system for tweets that both presents overall summaries and supports analysis of any variations that exists in the activity
              </p>
            </td>
          </tr>

            </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Industry Project</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle"><img src="images/Incheon_robot.jpeg" width="400"></td>
            <td width="75%" valign="center">
              <a href="https://jordanfraser.medium.com/the-robot-airport-workers-of-seoul-a08349f4f44e">Airstar - Incheon Airport Robot, LG Electronics</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:10%;vertical-align:middle">
              <img src="images/hyundai_chatbot.jpeg" width="400">
            </td>
            <td width="50%" valign="center">
              <a href="https://www.google.com/search?q=Hyundai+voice+chatbot+assistant&sxsrf=ALiCzsbUOf4VY0LEW_dMXU0Q5PCr2sp5TQ:1670517677094&source=lnms&tbm=isch&sa=X&ved=2ahUKEwj4wO-lu-r7AhWOHKYKHWP7DSIQ_AUoAXoECAEQAw&biw=1658&bih=813&dpr=1#imgrc=pJ1fp5jVtlHUvM">AI assistant for car, Hyundai</a>
              <br>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src="images/LG_thinQ.jpeg" width="400">
            </td>
            <td width="75%" valign="center">
              <a href="https://www.prnewswire.com/news-releases/lg-introduces-faster-advanced-customer-service-experience-with-proactive-support-300959483.html">Chatbot for home-appliances, LG Electronics </a>
              <br>
            </td>
          </tr>

        </tbody></table>

      </td>
    </tr>
  </table> 
</body>

</html>
